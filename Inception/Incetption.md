学习Inception系列的目的是Inception在设计网络结构上对深度和宽度的突破，跟attention注意力机制一样，都是网络设计中常用的技巧，是必须掌握的知识。
学习的内容主要是Inception Block的结构，这也是采用模块化设计的精髓所在。
Inception V1：
改善：Inception V1 提出了从提高网络计算资源的利用率，在计算量不变的情况下，提高网络的宽度和深度。
方法：对同一个输入特征采用不同的kernel size卷积核和max pooling进行特征的提取后在进行concat。并行结构增加网络的宽度，分支串行增加了网络的深度；每个通道采用不同大小的卷积核，可以采取到不同尺度的特征，获得不同的感受野大小；融合不同尺度的信息，可以得到更好的图像中特征。
Inception V2：
该版本采用小的卷积核代替大卷积核，解决了v1计算效率下降的问题。
提出：
1.特征维度要温和减少，避免维度下降过快，出现信息丢失。
2.浅层的网络不需要一开始就给定很高的维度，而是需要不断增加维度，并逐步增加非线性激活响应，可以获得更多解耦特征，浅层的低维度并不会损失过多信息，这也使得模型训练速度加快。
3.利用1x1卷积来快速降维，能减少输入尺寸来加快学习，降维是一种低损压缩，即使维度降低了，可以利用特征的相关性恢复出原有信息。

4.同时增加网络的深度和宽度，可以利用分支和并行结构，使网络获得性能的提升。

5.大卷积可以分解为多个小卷积，用2个3x3卷积来代替5x5卷积在保持感受野不变的同时降低了参数量。

6.非对称卷积nx1卷积核，利用3个3x1卷积来代替3x3卷积，nxn卷积可以通过1xn和nx1卷积替代，这种使用分解效果只有在中度大小的特征图上使用效果才会好，特征图大小在12-20之间最好。

7.并行结构，采用卷积池化并行执行后再合并的形式，降低模块的计算量。

8.v2相对v1的改变：小卷积代替大卷积；inception模块数量提升；每个inception同时采用avg和maxpooling；两个inception之间不再使用maxpooling；卷积层采用深度因子为8的可分离卷积，减少计算量，但增加内存消耗；加入了标签平滑

9.V3相对于v2的改变，增加了bn。

10. v4相对于v3的改变：增加了残差网络，尝试将inception与residual结合，提出了inception-resnet-v1和inception-resnet-v2网络。

Inception-Reset-v1：混合Inception版本，它的计算效率同Inception-v3；
Inception-ResNet-v2：更加昂贵的混合Inception版本，同明显改善了识别性能；
Inception-v4：没有残差链接的纯净Inception变种，性能如同Inception-ResNet-v2
我们研究了引入残差连接如何显著的提高inception网络的训练速度。而且仅仅凭借增加的模型尺寸，我们的最新的模型（带和不带残差连接）都优于我们以前的网络。









