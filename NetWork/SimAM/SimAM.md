SimAM在本文中，我们提出了一个用于卷积神经网络的概念简单但非常有效的注意模块。与现有的通道关注模块和空间关注模块相比，我们的模块无需向原始网络添加参数，而是在一层中推断特征图的3-D关注权重。具体来说，我们基于一些著名的神经科学理论，提出优化一个能量函数来发现每个神经元的重要性。我们进一步推导出能量函数的快速封闭形式的解，并表明该解可以在不到十行代码中实现。该模块的另一个优点是，大多数算子是根据定义的能量函数的解来选择的，避免了在结构调整上花费太多精力。通过对各种视觉任务的定量评估，证明了该模块的灵活性和有效性，提高了许多ConvNets的表达能力。